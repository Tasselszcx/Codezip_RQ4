import os
import json
import shutil
import time
import base64
from collections import Counter
from PIL import Image  # ç”¨äºæ‰‹åŠ¨å®ç°è§†è§‰å‹ç¼©
from data_miner import fetch_fresh_code 
import text_to_image_compact 

try:
    from openai import OpenAI
except Exception:
    OpenAI = None

# ================= é…ç½®åŒº =================
OUTPUT_DIR = "./experiment_output"
IMAGES_DIR = os.path.join(OUTPUT_DIR, "images")
TARGET_RATIOS = [1, 2, 4, 8]  # æˆ‘ä»¬çš„å‹ç¼©ç›®æ ‡

# ================= æ¨¡å—ä¸‰é…ç½®ï¼ˆInference Engineï¼‰=================
# åªè·‘ GLM-4.6Vï¼ˆé€šè¿‡ aihubmix OpenAI-compat æ¥å£ï¼‰
RUN_MODULE_3 = True
AIHUBMIX_BASE_URL = "https://aihubmix.com/v1"
GLM_MODEL_NAME = "glm-4.6v"
OCR_SYSTEM_PROMPT = "You are an OCR engine for code images."
OCR_USER_PROMPT = (
    "Transcribe the code in this image exactly.\n"
    "- Output plain text only (no Markdown, no code fences).\n"
    "- Preserve all whitespace, indentation, and newlines.\n"
    "- Do not add, remove, or rename anything.\n"
)
OCR_MAX_TOKENS = 4096
OCR_TEMPERATURE = 0.0
OCR_SLEEP_SECONDS = 0.2
OCR_MAX_RETRIES = 5
# =========================================

# ================= æ¨¡å—å››é…ç½®ï¼ˆAuto-Judgeï¼‰=================
RUN_MODULE_4 = True  # æ˜¯å¦è¿è¡Œè¯„ä¼°æ¨¡å—
JUDGE_LLM_MODEL = "gpt-5-mini"  # ç”¨äºsoft taxonomyåˆ†ç±»çš„æ¨¡å‹

# é”™è¯¯åˆ†ç±»ä½“ç³» (8ç±»)
ERROR_TAXONOMY = [
    "Visual_Typo",          # è§†è§‰ç›¸ä¼¼å­—ç¬¦æ›¿æ¢ï¼Œå¦‚ O/0, l/1
    "Symbol_Loss",          # æ ‡ç‚¹ç¬¦å·ä¸¢å¤±ï¼Œå¦‚ç¼ºå°‘æ‹¬å·ã€å†’å·
    "Indentation_Error",    # ç¼©è¿›é”™è¯¯
    "Line_Skipped",         # è·³è¡Œæ¼è¯»
    "Variable_Hallucination", # å˜é‡åå¹»è§‰ï¼Œå¦‚å°† 'data' è¯»æˆ 'date'
    "Code_Invention",       # å‡­ç©ºæé€ ä¸å­˜åœ¨çš„ä»£ç 
    "Repetition",           # é‡å¤è¾“å‡ºæŸäº›è¡Œ
    "Comment_Loss"          # æ³¨é‡Šå†…å®¹ä¸¢å¤±
]
# =========================================


def _mask_api_key(key: str) -> str:
    if not key:
        return ""
    if len(key) <= 12:
        return key[:2] + "..." + key[-2:]
    return key[:6] + "..." + key[-6:]


def _try_load_api_key_from_env_files() -> str:
    """ä» .env æ–‡ä»¶ä¸­å°è¯•è¯»å– AIHUBMIX_API_KEYã€‚

    ä¼˜å…ˆçº§ï¼šç¯å¢ƒå˜é‡ï¼ˆè°ƒç”¨æ–¹å¤„ç†ï¼‰> å·¥ä½œåŒºæ ¹ç›®å½• .env > ocr/.env
    """
    script_dir = os.path.dirname(__file__)
    repo_dir = os.path.abspath(os.path.join(script_dir, os.pardir))

    candidates = [
        os.path.join(os.getcwd(), ".env"),   # å–å†³äºä½ ä»å“ªé‡Œå¯åŠ¨
        os.path.join(repo_dir, ".env"),      # ä»“åº“æ ¹ç›®å½•ï¼ˆæ›´ç¨³ï¼‰
        os.path.join(script_dir, ".env"),    # ocr/.env
    ]

    for path in candidates:
        if not os.path.exists(path):
            continue
        try:
            with open(path, "r", encoding="utf-8") as f:
                for raw_line in f:
                    line = raw_line.strip()
                    if not line or line.startswith("#"):
                        continue
                    if "=" not in line:
                        continue
                    k, v = line.split("=", 1)
                    if k.strip() != "AIHUBMIX_API_KEY":
                        continue
                    value = v.strip().strip('"').strip("'")
                    if value:
                        return value
        except Exception:
            continue

    return ""


def _iter_image_files(root_dir: str):
    for dirpath, _, filenames in os.walk(root_dir):
        for fn in filenames:
            if fn.lower().endswith((".png", ".jpg", ".jpeg", ".webp")):
                yield os.path.join(dirpath, fn)


def _load_done_set(jsonl_path: str) -> set:
    done = set()
    if not os.path.exists(jsonl_path):
        return done
    try:
        with open(jsonl_path, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    obj = json.loads(line)
                    if obj.get("image_path"):
                        done.add(obj["image_path"])
                except Exception:
                    continue
    except Exception:
        return done
    return done


def _encode_image_to_data_url(image_path: str) -> str:
    ext = os.path.splitext(image_path)[1].lower()
    mime = "image/png"
    if ext in (".jpg", ".jpeg"):
        mime = "image/jpeg"
    elif ext == ".webp":
        mime = "image/webp"

    with open(image_path, "rb") as f:
        b64 = base64.b64encode(f.read()).decode("utf-8")
    return f"data:{mime};base64,{b64}"


def _parse_ratio_from_filename(image_path: str) -> int:
    # e.g. page_001_ratio2.png -> 2 ; page_001.png -> 1
    stem = os.path.splitext(os.path.basename(image_path))[0]
    marker = "_ratio"
    if marker in stem:
        try:
            return int(stem.split(marker, 1)[1])
        except Exception:
            return 1
    return 1


def run_module_3_glm46v(images_dir: str, output_dir: str):
    print("\n" + "=" * 40)
    print("ğŸš€ Running Module 3: Inference Engine (GLM-4.6V)")
    print("=" * 40)

    if OpenAI is None:
        print("âŒ Missing dependency: openai. Run: pip install openai")
        return

    api_key = os.getenv("AIHUBMIX_API_KEY")
    api_key_source = "env:AIHUBMIX_API_KEY" if api_key else ""
    if not api_key:
        api_key = _try_load_api_key_from_env_files()
        if api_key:
            api_key_source = "file:.env"
    if not api_key:
        searched = [
            os.path.join(os.getcwd(), ".env"),
            os.path.abspath(os.path.join(os.path.dirname(__file__), os.pardir, ".env")),
            os.path.join(os.path.dirname(__file__), ".env"),
        ]
        print("âŒ Missing AIHUBMIX_API_KEY.")
        print("   - æ–¹å¼1ï¼šPowerShell ä¸´æ—¶è®¾ç½®ï¼š$env:AIHUBMIX_API_KEY=\"sk-...\"")
        print("   - æ–¹å¼2ï¼šå†™å…¥ .env æ–‡ä»¶ï¼ˆä¸è¦æäº¤åˆ°ä»“åº“ï¼‰")
        print("     æ ¼å¼ï¼šAIHUBMIX_API_KEY=sk-...")
        print("     æŸ¥æ‰¾è·¯å¾„ï¼š")
        for p in searched:
            print(f"       - {p}")
        return

    print(f"ğŸ”‘ AIHUBMIX_API_KEY loaded ({api_key_source}): {_mask_api_key(api_key)}")

    os.makedirs(output_dir, exist_ok=True)
    out_jsonl = os.path.join(output_dir, "glm46v_ocr.jsonl")
    done = _load_done_set(out_jsonl)

    client = OpenAI(api_key=api_key, base_url=AIHUBMIX_BASE_URL)

    total = 0
    skipped = 0
    errors = 0

    image_paths = list(_iter_image_files(images_dir))
    print(f"ğŸ–¼ï¸  Total images to OCR: {len(image_paths)}")

    for i, image_path in enumerate(image_paths, start=1):
        print(f"[{i}/{len(image_paths)}] OCR: {os.path.basename(image_path)}")
        if image_path in done:
            skipped += 1
            continue

        # è·¯å¾„ç»“æ„: images/{code_id}/{variant_folder}/page_xxx.png
        # éœ€è¦å–ä¸Šä¸¤å±‚ç›®å½•æ‰æ˜¯ code_id
        parent_dir = os.path.dirname(image_path)            # .../1024x1500_hl_nl
        code_id_dir = os.path.dirname(parent_dir)           # .../{code_id}
        code_id = os.path.basename(code_id_dir)
        ratio = _parse_ratio_from_filename(image_path)

        data_url = _encode_image_to_data_url(image_path)

        last_err = None
        text = ""

        for attempt in range(1, OCR_MAX_RETRIES + 1):
            try:
                resp = client.chat.completions.create(
                    model=GLM_MODEL_NAME,
                    temperature=OCR_TEMPERATURE,
                    max_tokens=OCR_MAX_TOKENS,
                    messages=[
                        {"role": "system", "content": OCR_SYSTEM_PROMPT},
                        {
                            "role": "user",
                            "content": [
                                {"type": "text", "text": OCR_USER_PROMPT},
                                {"type": "image_url", "image_url": {"url": data_url}},
                            ],
                        },
                    ],
                )
                text = (resp.choices[0].message.content or "").rstrip()
                last_err = None
                break
            except Exception as e:
                last_err = str(e)
                # exponential backoff: 1,2,4,8,... capped at 30s
                backoff = min(30.0, float(2 ** (attempt - 1)))
                time.sleep(backoff)

        rec = {
            "code_id": code_id,
            "ratio": ratio,
            "image_path": image_path,
            "model": GLM_MODEL_NAME,
        }

        if last_err is None:
            rec["text"] = text
            total += 1
        else:
            rec["error"] = last_err
            errors += 1

        with open(out_jsonl, "a", encoding="utf-8") as f:
            f.write(json.dumps(rec, ensure_ascii=False) + "\n")

        time.sleep(OCR_SLEEP_SECONDS)

    print(f"âœ… Module 3 finished. ok={total}, skipped={skipped}, error={errors}")
    print(f"ğŸ“„ Output: {os.path.abspath(out_jsonl)}")


# ============================================================
# ğŸŸ  æ¨¡å—å››: Auto-Judge (è¯„ä¼°å™¨)
# ============================================================

def _compute_cer(reference: str, hypothesis: str) -> float:
    """
    è®¡ç®—å­—ç¬¦é”™è¯¯ç‡ (Character Error Rate)
    CER = (S + D + I) / N
    ä½¿ç”¨ Levenshtein ç¼–è¾‘è·ç¦»
    """
    ref = list(reference)
    hyp = list(hypothesis)
    n = len(ref)
    m = len(hyp)

    if n == 0:
        return 1.0 if m > 0 else 0.0

    # DP çŸ©é˜µ
    dp = [[0] * (m + 1) for _ in range(n + 1)]
    for i in range(n + 1):
        dp[i][0] = i
    for j in range(m + 1):
        dp[0][j] = j

    for i in range(1, n + 1):
        for j in range(1, m + 1):
            cost = 0 if ref[i - 1] == hyp[j - 1] else 1
            dp[i][j] = min(
                dp[i - 1][j] + 1,      # deletion
                dp[i][j - 1] + 1,      # insertion
                dp[i - 1][j - 1] + cost  # substitution
            )

    edit_distance = dp[n][m]
    return edit_distance / n


def _check_ast_parsable(code: str) -> bool:
    """æ£€æŸ¥ä»£ç æ˜¯å¦å¯è¢« Python AST è§£æ"""
    import ast
    try:
        ast.parse(code)
        return True
    except SyntaxError:
        return False


def _compute_token_bleu(reference: str, hypothesis: str) -> float:
    """
    è®¡ç®—åŸºäº token çš„ç®€åŒ– BLEU (CodeBLEU æ ¸å¿ƒ)
    ä½¿ç”¨ 1-gram åˆ° 4-gram çš„å‡ ä½•å¹³å‡
    """
    import re
    from collections import Counter
    import math

    def tokenize(text):
        # ç®€å•çš„ä»£ç åˆ†è¯ï¼šæŒ‰éå­—æ¯æ•°å­—å­—ç¬¦åˆ†å‰²
        return re.findall(r'\w+|[^\w\s]', text)

    ref_tokens = tokenize(reference)
    hyp_tokens = tokenize(hypothesis)

    if len(hyp_tokens) == 0:
        return 0.0

    # è®¡ç®— n-gram precision
    def ngram_precision(ref_toks, hyp_toks, n):
        if len(hyp_toks) < n:
            return 0.0
        ref_ngrams = Counter(tuple(ref_toks[i:i+n]) for i in range(len(ref_toks) - n + 1))
        hyp_ngrams = Counter(tuple(hyp_toks[i:i+n]) for i in range(len(hyp_toks) - n + 1))

        match = 0
        total = 0
        for ng, cnt in hyp_ngrams.items():
            match += min(cnt, ref_ngrams.get(ng, 0))
            total += cnt
        return match / total if total > 0 else 0.0

    # è®¡ç®— 1-gram åˆ° 4-gram çš„ precision
    precisions = []
    for n in range(1, 5):
        p = ngram_precision(ref_tokens, hyp_tokens, n)
        precisions.append(p)

    # è¿‡æ»¤æ‰ 0 å€¼ï¼ˆé¿å… log(0)ï¼‰
    non_zero = [p for p in precisions if p > 0]
    if not non_zero:
        return 0.0

    # å‡ ä½•å¹³å‡
    log_avg = sum(math.log(p) for p in non_zero) / len(non_zero)
    bleu = math.exp(log_avg)

    # Brevity penalty
    bp = min(1.0, math.exp(1 - len(ref_tokens) / len(hyp_tokens))) if len(hyp_tokens) > 0 else 0.0

    return bp * bleu


def _call_llm_for_taxonomy(client, reference: str, hypothesis: str) -> list:
    """
    è°ƒç”¨ LLM è¿›è¡Œé”™è¯¯åˆ†ç±»
    è¿”å›æ£€æµ‹åˆ°çš„é”™è¯¯ç±»å‹åˆ—è¡¨
    """
    prompt = f"""You are an expert code quality evaluator. 
Compare the reference code with the OCR output and identify error types.

Reference code:
```
{reference[:3000]}
```

OCR output:
```
{hypothesis[:3000]}
```

Analyze the differences and return ONLY a JSON array of error types from this list:
{ERROR_TAXONOMY}

Rules:
- Return an empty array [] if the output matches the reference perfectly
- Only include error types that are clearly present
- Return ONLY the JSON array, no other text

Example response: ["Visual_Typo", "Symbol_Loss"]
"""

    try:
        resp = client.chat.completions.create(
            model=JUDGE_LLM_MODEL,
            messages=[{"role": "user", "content": prompt}],
            max_completion_tokens=256,
            temperature=0.0,
        )
        content = resp.choices[0].message.content.strip()
        # è§£æ JSON
        import re
        match = re.search(r'\[.*?\]', content, re.DOTALL)
        if match:
            return json.loads(match.group())
        return []
    except Exception as e:
        print(f"   âš ï¸ LLM taxonomy call failed: {e}")
        return []


def run_module_4_judge(output_dir: str):
    """
    æ¨¡å—4: Auto-Judge è¯„ä¼°å™¨
    è¯»å– OCR ç»“æœï¼Œä¸åŸå§‹ä»£ç å¯¹æ¯”ï¼Œè¾“å‡ºè¯„ä¼°æŒ‡æ ‡
    """
    print("\n" + "=" * 40)
    print("ğŸš€ Running Module 4: Auto-Judge")
    print("=" * 40)

    # è¯»å– dataset.json (åŸå§‹ä»£ç )
    dataset_path = os.path.join(output_dir, "dataset.json")
    if not os.path.exists(dataset_path):
        print("âŒ dataset.json not found, skipping Module 4")
        return

    with open(dataset_path, "r", encoding="utf-8") as f:
        dataset = json.load(f)

    # å»ºç«‹ code_id -> code çš„æ˜ å°„
    code_map = {item["id"]: item["code"] for item in dataset}

    # è¯»å– OCR ç»“æœ
    ocr_path = os.path.join(output_dir, "glm46v_ocr.jsonl")
    if not os.path.exists(ocr_path):
        print("âŒ glm46v_ocr.jsonl not found, skipping Module 4")
        return

    ocr_results = []
    with open(ocr_path, "r", encoding="utf-8") as f:
        for line in f:
            if line.strip():
                ocr_results.append(json.loads(line))

    # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯ (ç”¨äº taxonomy)
    api_key = os.environ.get("AIHUBMIX_API_KEY") or _try_load_api_key_from_env_files()
    client = None
    if api_key and OpenAI:
        client = OpenAI(api_key=api_key, base_url=AIHUBMIX_BASE_URL)

    # è¯„ä¼°ç»“æœ
    detail_path = os.path.join(output_dir, "judge_results_detail.jsonl")
    summary_path = os.path.join(output_dir, "judge_summary.json")

    # æŒ‰ ratio åˆ†ç»„ç»Ÿè®¡
    stats_by_ratio = {r: {"cer_sum": 0, "bleu_sum": 0, "ast_pass": 0, "count": 0, "errors": Counter()} 
                      for r in TARGET_RATIOS}

    # æ¸…ç©º detail æ–‡ä»¶
    open(detail_path, "w").close()

    total = len(ocr_results)
    for idx, rec in enumerate(ocr_results):
        ratio = rec.get("ratio", 1)
        ocr_text = rec.get("text", "")

        # ä» image_path é‡æ–°æå–æ­£ç¡®çš„ code_id
        # è·¯å¾„ç»“æ„: images/{code_id}/{variant_folder}/page_xxx.png
        img_path = rec.get("image_path", "")
        parts = img_path.replace("\\", "/").split("/")
        code_id = parts[-3] if len(parts) >= 3 else rec.get("code_id", "")

        if not ocr_text or "error" in rec:
            continue

        reference = code_map.get(code_id, "")
        if not reference:
            continue

        print(f"[{idx + 1}/{total}] Evaluating: {code_id} @ ratio {ratio}")

        # 1. Hard metrics
        cer = _compute_cer(reference, ocr_text)
        ast_ok = _check_ast_parsable(ocr_text)
        bleu = _compute_token_bleu(reference, ocr_text)

        # 2. Soft taxonomy (LLM)
        error_types = []
        if client:
            error_types = _call_llm_for_taxonomy(client, reference, ocr_text)

        # è®°å½•è¯¦æƒ…
        detail_rec = {
            "code_id": code_id,
            "ratio": ratio,
            "cer": round(cer, 4),
            "ast_parsable": ast_ok,
            "token_bleu": round(bleu, 4),
            "error_types": error_types
        }

        with open(detail_path, "a", encoding="utf-8") as f:
            f.write(json.dumps(detail_rec, ensure_ascii=False) + "\n")

        # æ›´æ–°ç»Ÿè®¡
        if ratio in stats_by_ratio:
            stats_by_ratio[ratio]["cer_sum"] += cer
            stats_by_ratio[ratio]["bleu_sum"] += bleu
            stats_by_ratio[ratio]["ast_pass"] += int(ast_ok)
            stats_by_ratio[ratio]["count"] += 1
            for et in error_types:
                stats_by_ratio[ratio]["errors"][et] += 1

    # ç”Ÿæˆæ±‡æ€»
    summary = {}
    for ratio, s in stats_by_ratio.items():
        if s["count"] == 0:
            continue
        summary[f"ratio_{ratio}x"] = {
            "count": s["count"],
            "avg_cer": round(s["cer_sum"] / s["count"], 4),
            "avg_token_bleu": round(s["bleu_sum"] / s["count"], 4),
            "ast_pass_rate": round(s["ast_pass"] / s["count"], 4),
            "error_distribution": dict(s["errors"])
        }

    with open(summary_path, "w", encoding="utf-8") as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)

    print(f"\nâœ… Module 4 finished.")
    print(f"ğŸ“„ Detail: {os.path.abspath(detail_path)}")
    print(f"ğŸ“Š Summary: {os.path.abspath(summary_path)}")

    # æ‰“å°ç®€è¦æ±‡æ€»
    print("\nğŸ“ˆ Quick Summary:")
    for ratio_key, data in summary.items():
        print(f"   {ratio_key}: CER={data['avg_cer']:.2%}, BLEU={data['avg_token_bleu']:.4f}, "
              f"AST Pass={data['ast_pass_rate']:.0%}")


def apply_visual_corruption(image_path, ratio):
    """
    æ‰‹åŠ¨å®ç°è§†è§‰å¹²æ‰°å™¨ï¼šè¯»å–åŸå›¾ï¼Œå…ˆæŒ‰æ¯”ä¾‹ç¼©å°å†æ”¾å¤§å›åŸå°ºå¯¸ï¼ˆä¿æŒå°ºå¯¸ä¸€è‡´ï¼‰
    """
    if ratio == 1:
        return image_path
    
    try:
        with Image.open(image_path) as img:
            # è®¡ç®—æ–°å°ºå¯¸
            original_w, original_h = img.size
            new_w = max(1, int(original_w / ratio))
            new_h = max(1, int(original_h / ratio))
            
            # æ‰§è¡Œå‹ç¼© (Downsampling) -> å† Upsampling å›åŸå°ºå¯¸
            # è¿™æ ·å¯ä»¥ä¿æŒå°ºå¯¸ä¸€è‡´ï¼ŒåŒæ—¶é€šè¿‡ä¿¡æ¯ä¸¢å¤±åˆ¶é€ â€œå˜ç³Šâ€æ•ˆæœ
            small_img = img.resize((new_w, new_h), Image.Resampling.BILINEAR)
            resized_img = small_img.resize((original_w, original_h), Image.Resampling.BILINEAR)
            
            # æ„é€ æ–°æ–‡ä»¶å: page_001.png -> page_001_ratio2.png
            dir_name = os.path.dirname(image_path)
            base_name = os.path.basename(image_path)
            name_part, ext = os.path.splitext(base_name)
            new_filename = f"{name_part}_ratio{ratio}{ext}"
            new_path = os.path.join(dir_name, new_filename)
            
            resized_img.save(new_path)
            return new_path
    except Exception as e:
        print(f"   âš ï¸ Compression failed for ratio {ratio}: {e}")
        return None

def run_full_process():
    # 0. æ¸…ç†ç¯å¢ƒ
    if os.path.exists(OUTPUT_DIR):
        try:
            shutil.rmtree(OUTPUT_DIR)
        except:
            pass # æœ‰æ—¶å€™æ–‡ä»¶å ç”¨åˆ ä¸æ‰ï¼Œå¿½ç•¥
    os.makedirs(IMAGES_DIR, exist_ok=True)

    # -------------------------------------------------
    # ğŸŸ¢ æ¨¡å—ä¸€: æ•°æ®æŒ–æ˜ (Data Miner)
    # -------------------------------------------------
    print("\n" + "="*40)
    print("ğŸš€ Running Module 1: Data Miner")
    print("="*40)
    
    dataset = fetch_fresh_code()
    
    if not dataset:
        print("âŒ No data found.")
        return

    dataset_path = os.path.join(OUTPUT_DIR, "dataset.json")
    with open(dataset_path, "w", encoding="utf-8") as f:
        json.dump(dataset, f, indent=2, ensure_ascii=False)

    # -------------------------------------------------
    # ğŸ”µ æ¨¡å—äºŒ: è§†è§‰å¹²æ‰°å™¨ (Visual Corruptor)
    # -------------------------------------------------
    print("\n" + "="*40)
    print("ğŸš€ Running Module 2: Visual Corruptor")
    print(f"ğŸ¯ Target Ratios: {TARGET_RATIOS}")
    print("="*40)

    total_images_generated = 0
    
    for idx, item in enumerate(dataset):
        code_id = item['id']
        source_code = item['code']
        
        print(f"[{idx+1}/{len(dataset)}] Processing: {code_id} ...")
        
        item_output_dir = os.path.join(IMAGES_DIR, code_id)
        os.makedirs(item_output_dir, exist_ok=True)
        
        temp_file_path = os.path.join(item_output_dir, "temp_source.py")
        with open(temp_file_path, "w", encoding="utf-8") as f:
            f.write(source_code)
            
        try:
            # 1. ç”ŸæˆåŸºå‡†é«˜æ¸…å›¾ (1x)
            # ä½¿ç”¨æ‚¨æä¾›çš„å‡½æ•°å®šä¹‰ï¼Œæ³¨æ„å‚æ•°åå˜åŒ–
            generated_paths = text_to_image_compact.generate_images_for_file(
                filename=temp_file_path,
                source_code=source_code,
                base_output_dir=item_output_dir,
                width=1024,
                height=1500,
                font_size=16, 
                line_height=1.2,
                dpi=100,
                # ğŸŒŸ å…³é”®ä¿®æ”¹ï¼šæ”¹ä¸º Trueï¼Œä¿æŒä»£ç åŸæ ·æ¢è¡Œ ğŸŒŸ
                preserve_newlines=True,  
                enable_syntax_highlight=True,
                unique_id="base"
            )
            
            if not generated_paths:
                print("   âŒ No base image generated.")
                continue

            # 2. æ‰§è¡Œè§†è§‰å‹ç¼©å¾ªç¯ (1x, 2x, 4x, 8x)
            # æ—¢ç„¶ generate_images_for_file åªèƒ½ç”Ÿæˆä¸€ç§ï¼Œæˆ‘ä»¬åœ¨å¤–é¢æ‰‹åŠ¨å‹ç¼©
            for original_path in generated_paths:
                for ratio in TARGET_RATIOS:
                    if ratio == 1:
                        # 1x å°±æ˜¯åŸå›¾ï¼Œä¸ç”¨åŠ¨ï¼Œæˆ–è€…é‡å‘½åä¸€ä¸‹æ–¹ä¾¿ç»Ÿä¸€
                        total_images_generated += 1
                        continue
                    
                    # ç”Ÿæˆå˜ç³Šçš„å›¾
                    new_path = apply_visual_corruption(original_path, ratio)
                    if new_path:
                        # print(f"      -> Generated {ratio}x compressed: {os.path.basename(new_path)}")
                        total_images_generated += 1

        except Exception as e:
            print(f"   âŒ Error processing {code_id}: {e}")
            import traceback
            traceback.print_exc()
        finally:
            if os.path.exists(temp_file_path):
                os.remove(temp_file_path)

    print("\n" + "="*40)
    print("ğŸ‰ Pipeline Stage 1 & 2 Completed!")
    print(f"ğŸ“Š Summary:")
    print(f"   - Data Mined: {len(dataset)}")
    print(f"   - Total Variants Generated: {total_images_generated}")
    print(f"   - Output Location: {os.path.abspath(OUTPUT_DIR)}")
    print("="*40)

    # -------------------------------------------------
    # ğŸŸ£ æ¨¡å—ä¸‰: æ¨ç†å¼•æ“ (Inference Engine) - GLM-4.6V
    # -------------------------------------------------
    if RUN_MODULE_3:
        run_module_3_glm46v(IMAGES_DIR, OUTPUT_DIR)

    # -------------------------------------------------
    # ğŸŸ  æ¨¡å—å››: è‡ªåŠ¨è¯„ä¼°å™¨ (Auto-Judge)
    # -------------------------------------------------
    if RUN_MODULE_4:
        run_module_4_judge(OUTPUT_DIR)

if __name__ == "__main__":
    run_full_process()