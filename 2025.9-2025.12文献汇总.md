### 📋 2025 Q4 Arxiv Top 20: AI & LLM Agents (2025.09 - 2025.12)

| Title | Authors | Pub. Date | Arxiv ID | Abstract (核心贡献概括) |
| :--- | :--- | :--- | :--- | :--- |
| **Agentic Software Engineering: Foundational Pillars and a Research Roadmap** | Ahmed E. Hassan et al. | 2025-09-07 | [2509.06216](http://arxiv.org/abs/2509.06216v2) | **[软件工程/综述]** 定义了 SE 3.0 "Agentic Software Engineering" 的新时代。不再是简单的代码生成，而是强调“SE for Agents”和“Agents for SE”的双向共生。提出了 ACE（指挥环境）和 AEE（执行环境）两大工作台概念，为未来基于智能体的软件开发确立了理论框架。 |
| **Agentic Refactoring: An Empirical Study of AI Coding Agents** | Kosei Horikawa et al. | 2025-11-06 | [2511.04824](http://arxiv.org/abs/2511.04824v1) | **[代码重构/实证]** 分析了开源项目中 1.5 万次由 AI Agent（如 Claude Code）执行的重构。发现 26% 的 Agent 提交明确针对重构，但主要集中在局部代码质量（如变量重命名），而非架构优化，揭示了当前 Agent 在深层代码理解上的局限。 |
| **ToM-SWE: User Mental Modeling For Software Engineering Agents** | Xuhui Zhou et al. | 2025-10-24 | [2510.21903](http://arxiv.org/abs/2510.21903v1) | **[心智理论/协作]** 提出了一种双智能体架构，引入专门的“心智理论（ToM）”智能体来模拟用户的意图、偏好和潜在需求。在有状态的编程任务中，该机制将成功率从 18.1% 提升至 59.7%，显著改善了人机协作体验。 |
| **LoCoBench-Agent: An Interactive Benchmark for LLM Agents in Long-Context Software Engineering** | Jielin Qiu et al. | 2025-11-17 | [2511.13998](http://arxiv.org/abs/2511.13998v1) | **[基准测试/长文本]** 针对软件工程中的长上下文问题（10K-1M tokens），提出了交互式基准测试 LoCoBench-Agent。评估揭示了 Agent 在深入探索（提高理解力）与快速响应（提高效率）之间的权衡，以及工具使用策略对长程任务稳定性的影响。 |
| **Software Engineering Agents for Embodied Controller Generation** | Timothé Boulet et al. | 2025-10-24 | [2510.21902](http://arxiv.org/abs/2510.21902v1) | **[具身智能/代码]** 将 SWE-Agent（软件工程智能体）的能力迁移至具身控制领域。在 MiniGrid 环境中，研究发现仅靠静态代码分析不足以生成高质量控制器，动态环境探索能力对于“编写能够控制机器人的代码”至关重要。 |
| **Automated Penetration Testing with LLM Agents and Classical Planning (CHECKMATE)** | Lingzhi Wang et al. | 2025-12-11 | [2512.11143](http://arxiv.org/abs/2512.11143v1) | **[网络安全/攻防]** 发现现有 LLM Agent 在长程攻击规划中存在缺陷。提出了 CHECKMATE 框架，结合经典自动化规划（Classical Planning）作为“外脑”来指导 LLM，使渗透测试的成功率超越 SOTA 模型（Claude Code）20% 以上，大幅降低了攻击成本。 |
| **AI Kill Switch for malicious web-based LLM agent (AutoGuard)** | Sechan Lee et al. | 2025-09-26 | [2511.13725](http://arxiv.org/abs/2511.13725v2) | **[防御机制]** 提出了一种针对恶意 Web 爬虫 Agent 的“AI Kill Switch”。通过在网页 DOM 中透明植入隐蔽的防御 Prompt（对人类不可见），触发入侵 Agent 的安全机制使其自动终止任务。该方法对 GPT-4o 等先进模型实现了 >80% 的防御成功率。 |
| **LLM Agents for Automated Web Vulnerability Reproduction: Are We There Yet?** | Bin Liu et al. | 2025-10-16 | [2510.14700](http://arxiv.org/abs/2510.14700v1) | **[漏洞复现/测评]** 测评了 20 种主流 Agent 在复现真实 Web 漏洞（CVE）方面的能力。结论相当悲观：尽管在简单库漏洞上表现尚可，但在需要多组件交互、身份认证的复杂服务级漏洞复现中，现有 Agent 普遍失败，即使是顶尖模型也极度依赖人工引导。 |
| **Bilevel Optimization for Covert Memory Tampering in Heterogeneous Multi-Agent Architectures (XAMT)** | Akhil Sharma et al. | 2025-12-15 | [2512.15790](http://arxiv.org/abs/2512.15790v1) | **[对抗攻击/记忆]** 揭示了多智能体系统的新型安全威胁：针对“中央记忆库”（如 RAG 知识库或经验回放池）的隐蔽篡改。通过双层优化攻击，仅需污染 <1% 的数据即可在不被检测的情况下操纵整个多智能体系统的行为。 |
| **Safe, Untrusted, "Proof-Carrying" AI Agents: toward the agentic lakehouse** | Jacopo Tagliabue et al. | 2025-10-10 | [2510.09567](http://arxiv.org/abs/2510.09567v1) | **[基础设施/信任]** 探讨如何在企业核心数据平台（Data Lakehouse）中运行不可信的第三方 Agent。提出“Proof-Carrying”机制，要求 Agent 在提交代码或操作时附带“正确性证明”，从而在零信任环境下实现安全的自动化数据处理。 |
| **Multi-Agent Deep Research: Training Multi-Agent Systems with M-GRPO** | Haoyang Hong et al. | 2025-11-17 | [2511.13288](http://arxiv.org/abs/2511.13288v2) | **[训练方法/Deep Research]** 提出了 M-GRPO（多智能体组相对策略优化），用于训练由“规划者”和“工具执行者”组成的垂直分层多智能体系统。该方法解决了不同角色 Agent 训练节奏不一致的问题，显著提升了 Deep Research（深度调研）类任务的稳定性。 |
| **Single-Agent Scaling Fails Multi-Agent Intelligence** | Shuyue Hu et al. | 2025-12-09 | [2512.08743](http://arxiv.org/abs/2512.08743v3) | **[多智能体/Scaling Law]** 对 41 个 LLM 进行测试，得出一个反直觉结论：仅仅提升单体 LLM 的能力（Scaling）并不能自然涌现出多智能体协作能力。多智能体特有的沟通、协调和适应能力需要专门的训练范式，单体强不等于团队强。 |
| **AOAD-MAT: Transformer-based multi-agent deep reinforcement learning...** | Shota Takayama et al. | 2025-10-15 | [2510.13343](http://arxiv.org/abs/2510.13343v1) | **[强化学习/协作]** 针对多智能体协作中的“抢跑”问题，提出了显式建模“行动决策顺序”的 Transformer 模型。通过动态调整 Agent 的行动次序，而非同时行动，显著提升了在星际争霸（StarCraft）等复杂环境中的协作效率。 |
| **ARCANE: A Multi-Agent Framework for Interpretable and Configurable Alignment** | Charlie Masters et al. | 2025-12-05 | [2512.06196](http://arxiv.org/abs/2512.06196v1) | **[AI对齐/治理]** 将 AI 对齐视为多智能体协作过程。ARCANE 框架能根据任务动态生成自然语言评分标准（Rubrics），实现了在不重新训练模型的情况下，可配置、可解释地约束 Agent 行为，满足不同利益相关者的偏好。 |
| **Hierarchical Multi-agent Large Language Model Reasoning for Autonomous Functional Materials Discovery (MASTER)** | Samuel Rothfarb et al. | 2025-12-15 | [2512.13930](http://arxiv.org/abs/2512.13930v1) | **[科学发现/材料]** 介绍了 MASTER 框架，通过层级化的多智能体（如同行评审员、排序专员）协作，指导新材料的自主发现。在电子结构推理任务中，该框架减少了 90% 昂贵的物理模拟计算量，展示了 Agent 在硬科技领域的潜力。 |
| **Thucy: An LLM-based Multi-Agent System for Claim Verification across Relational Databases** | Michael Theologitis et al. | 2025-12-02 | [2512.03278](http://arxiv.org/abs/2512.03278v1) | **[事实验证]** 这是一个跨数据库、跨表格的事实验证系统。Thucy 智能体能自主探索陌生的数据库结构，生成精确的 SQL 查询来验证复杂主张（如政治或经济声明），并提供数据证据，准确率超越 SOTA 5.6%。 |
| **A Cybersecurity AI Agent Selection and Decision Support Framework** | Masike Malatji | 2025-10-02 | [2510.01751](http://arxiv.org/abs/2510.01751v1) | **[决策支持]** 将 NIST 网络安全框架 2.0 与 AI Agent 架构进行对齐。为企业提供了一套标准化的决策矩阵，用于在“反应式”、“认知式”等不同类型 Agent 中进行选择，以应对特定的安全威胁。 |
| **Peer-to-Peer Energy Trading in Dairy Farms using Multi-Agent Reinforcement Learning** | Mian Ibad Ali Shah et al. | 2025-11-28 | [2511.23148](http://arxiv.org/abs/2511.23148v1) | **[能源/应用]** 也是 Agent 应用落地的典型案例。利用多智能体强化学习（DQN/PPO）管理奶牛场的点对点能源交易。通过价格顾问 Agent 和拍卖机制，成功降低了 14% 的电力成本并削减了 50% 的峰值需求。 |
| **Opponent Shaping in LLM Agents** | Marta Emili Garcia Segura et al. | 2025-10-09 | [2510.08255](http://arxiv.org/abs/2510.08255v1) | **[博弈论/行为学]** 研究了 LLM Agent 是否具备“塑造对手（Opponent Shaping）”的能力。实验表明，ShapeLLM Agent 能够在博弈（如囚徒困境）中主动引导对手进入特定的学习轨迹，实现己方利益最大化或集体最优。 |
| **A Comprehensive Empirical Evaluation of Agent Frameworks on Code-centric Tasks** | Zhuowen Yin et al. | 2025-11-02 | [2511.00872](http://arxiv.org/abs/2511.00872v1) | **[框架评测]** 对 7 种主流通用 Agent 框架（如 OpenHands, GPTswarm）进行了详尽评测。结论显示：没有任何一个框架是万能的，成本（Token消耗）、效率（轨迹长度）和效果（代码质量）之间存在显著的“不可能三角”。 |